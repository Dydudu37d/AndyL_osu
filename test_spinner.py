import os
import torch
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import torch.nn as nn

# ç¡®ä¿è®¾å¤‡é…ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# æµ‹è¯•å›¾åƒè·¯å¾„
TEST_IMG_PATH = 'test_img'
TRAIN_IMG_PATH = 'train_img'

# ç›´æ¥å®šä¹‰æ‰€éœ€çš„é…ç½®
CONFIG = {
    'num_classes': 4,
    'class_names': ['circle', 'slider', 'spinner', 'back'],
    'image_size': (160, 90),
    'batch_size': 128,
    'num_epochs': 50
}

# ç›´æ¥å®šä¹‰OsuNetæ¨¡å‹ç±»ï¼Œä¸main.pyä¸­çš„å®Œå…¨ä¸€è‡´
class OsuNet(nn.Module):
    """Osuæ¸¸æˆå¯¹è±¡åˆ†ç±»ç½‘ç»œ - ä¼˜åŒ–ï¼šç®€åŒ–ç½‘ç»œç»“æ„ï¼Œå‡å°‘è®¡ç®—é‡"""
    def __init__(self, num_classes=CONFIG['num_classes']):
        super().__init__()
        self.num_classes = num_classes
        
        # ç®€åŒ–çš„å·ç§¯éª¨å¹²ç½‘ç»œï¼Œå‡å°‘é€šé“æ•°å’Œå±‚æ•°
        self.backbone = nn.Sequential(
            # è¾“å…¥ 3x160x90 -> è¾“å‡º 16x80x45
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # è¾“å…¥ 16x80x45 -> è¾“å‡º 32x40x22
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # è¾“å…¥ 32x40x22 -> è¾“å‡º 64x20x11
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # è¾“å…¥ 64x20x11 -> è¾“å‡º 128x10x5
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        # ç®€åŒ–çš„åˆ†ç±»å¤´ï¼Œå‡å°‘ç¥ç»å…ƒæ•°é‡å’Œdropoutå±‚
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # å…¨å±€å¹³å‡æ± åŒ–ï¼Œè¾“å‡º [batch_size, 128, 1, 1]
            nn.Flatten(),  # å±•å¹³ä¸º [batch_size, 128]
            nn.Linear(128, 64),  # å‡å°‘ç¥ç»å…ƒæ•°é‡
            nn.ReLU(inplace=True),
            nn.Linear(64, num_classes)  # ç›´æ¥è¾“å‡ºåˆ†ç±»ç»“æœ
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
    
    def _initialize_weights(self):
        """ä¼˜åŒ–çš„æƒé‡åˆå§‹åŒ–æ–¹æ³•"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                # ä½¿ç”¨Kaimingåˆå§‹åŒ–ä»£æ›¿é»˜è®¤çš„æ­£æ€åˆ†å¸ƒï¼Œæ›´é€‚åˆReLUæ¿€æ´»å‡½æ•°
                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        features = self.backbone(x)
        predictions = self.classifier(features)
        return predictions

# åŠ è½½æ¨¡å‹
model = OsuNet(num_classes=CONFIG['num_classes'])
model_path = 'models/osu_model.pth'

if os.path.exists(model_path):
    try:
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        # åŠ è½½æ¨¡å‹æƒé‡ï¼Œå¤„ç†ç±»åˆ«æ•°é‡ä¸åŒ¹é…çš„æƒ…å†µ
        checkpoint = torch.load(model_path, map_location=device)
        model_dict = model.state_dict()
        
        # è¿‡æ»¤æ‰ä¸åŒ¹é…çš„æƒé‡ï¼ˆä¸»è¦æ˜¯åˆ†ç±»å™¨çš„æœ€åä¸€å±‚ï¼‰
        filtered_checkpoint = {k: v for k, v in checkpoint.items() if k in model_dict and v.shape == model_dict[k].shape}
        
        # æ›´æ–°æ¨¡å‹æƒé‡
        model_dict.update(filtered_checkpoint)
        model.load_state_dict(model_dict, strict=False)
        
        model.to(device)
        model.eval()
        print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"åŠ è½½äº† {len(filtered_checkpoint)} ä¸ªåŒ¹é…çš„æƒé‡ï¼Œè·³è¿‡äº† {len(checkpoint) - len(filtered_checkpoint)} ä¸ªä¸åŒ¹é…çš„æƒé‡")
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        exit()
else:
    print("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
    exit()

# é¢„å¤„ç†å›¾åƒå‡½æ•°
def preprocess_image(image_path):
    """é¢„å¤„ç†å•å¼ å›¾åƒä»¥ä¾›æ¨¡å‹è¾“å…¥"""
    image = Image.open(image_path).convert('RGB')
    image = image.resize(CONFIG['image_size'])
    image = np.array(image)
    image = image / 255.0
    image = np.transpose(image, (2, 0, 1))
    # åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„Normalizeå˜æ¢
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = (image - mean[:, None, None]) / std[:, None, None]
    image = torch.tensor(image, dtype=torch.float32)
    image = image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    return image.to(device)

# æµ‹è¯•æ¨¡å‹å‡½æ•°
def test_model(image_path, true_label=None):
    """æµ‹è¯•æ¨¡å‹åœ¨å•å¼ å›¾åƒä¸Šçš„è¡¨ç°"""
    # é¢„å¤„ç†å›¾åƒ
    input_image = preprocess_image(image_path)
    
    # æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        outputs = model(input_image)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        pred_label = torch.argmax(probabilities).item()
        pred_prob = probabilities[0][pred_label].item()
    
    return pred_label, pred_prob

# è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—è¯¦ç»†æŒ‡æ ‡
def evaluate_model_performance():
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰è¯¦ç»†æŒ‡æ ‡"""
    # è·å–æ‰€æœ‰ç±»åˆ«çš„å›¾åƒ
    categories = [1, 2, 3, 4]  # ç±»åˆ«ç›®å½•
    category_labels = [0, 1, 2, 3]  # æ¨¡å‹é¢„æµ‹çš„æ ‡ç­¾
    category_names = CONFIG['class_names']
    
    # åˆå§‹åŒ–æ··æ·†çŸ©é˜µ
    num_classes = len(category_names)
    confusion_matrix = [[0 for _ in range(num_classes)] for _ in range(num_classes)]
    
    # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ
    all_true_labels = []
    all_pred_labels = []
    all_pred_probs = []
    image_paths = []
    
    print("\n===== å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½ =====")
    
    # éå†æ‰€æœ‰ç±»åˆ«ç›®å½•
    for cat_dir in categories:
        true_label = cat_dir - 1  # ç›®å½•1->circle(0), 2->slider(1), 3->spinner(2)
        cat_path = os.path.join(TRAIN_IMG_PATH, str(cat_dir))
        
        if not os.path.exists(cat_path):
            continue
        
        # è·å–è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰å›¾åƒ
        images = [os.path.join(cat_path, f) for f in os.listdir(cat_path) if f.endswith('.png')]
        
        for img_path in images:
            pred_label, pred_prob = test_model(img_path)
            
            # æ›´æ–°æ··æ·†çŸ©é˜µ
            confusion_matrix[true_label][pred_label] += 1
            
            # æ”¶é›†ç»“æœ
            all_true_labels.append(true_label)
            all_pred_labels.append(pred_label)
            all_pred_probs.append(pred_prob)
            image_paths.append(img_path)
            
            # æ‰“å°é¢„æµ‹ç»“æœ
            true_name = category_names[true_label]
            pred_name = category_names[pred_label]
            if pred_label == true_label:
                result = "âœ… æ­£ç¡®"
            else:
                result = "âŒ é”™è¯¯"
            print(f"{img_path}: çœŸå®ç±»åˆ«={true_name}, é¢„æµ‹ç±»åˆ«={pred_name} ({pred_prob:.4f}) - {result}")
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    print("\n===== æ··æ·†çŸ©é˜µ =====")
    print(f"{'':<12}", end="")
    for name in category_names:
        print(f"{name:<12}", end="")
    print()
    
    for i in range(num_classes):
        print(f"{category_names[i]:<12}", end="")
        for j in range(num_classes):
            print(f"{confusion_matrix[i][j]:<12}", end="")
        print()
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    print("\n===== ç±»åˆ«çº§æŒ‡æ ‡ =====")
    precision = []
    recall = []
    f1 = []
    accuracy = []
    
    for i in range(num_classes):
        # çœŸé˜³æ€§
        tp = confusion_matrix[i][i]
        # å‡é˜³æ€§ï¼ˆå…¶ä»–ç±»åˆ«é¢„æµ‹ä¸ºå½“å‰ç±»åˆ«ï¼‰
        fp = sum(confusion_matrix[j][i] for j in range(num_classes) if j != i)
        # å‡é˜´æ€§ï¼ˆå½“å‰ç±»åˆ«é¢„æµ‹ä¸ºå…¶ä»–ç±»åˆ«ï¼‰
        fn = sum(confusion_matrix[i][j] for j in range(num_classes) if j != i)
        # çœŸé˜´æ€§
        tn = sum(confusion_matrix[j][k] for j in range(num_classes) for k in range(num_classes) if j != i and k != i)
        
        # è®¡ç®—æŒ‡æ ‡
        class_precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        class_recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0
        class_accuracy = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0
        
        precision.append(class_precision)
        recall.append(class_recall)
        f1.append(class_f1)
        accuracy.append(class_accuracy)
        
        print(f"ç±»åˆ«: {category_names[i]}")
        print(f"  å‡†ç¡®ç‡: {class_accuracy:.2%}")
        print(f"  ç²¾ç¡®ç‡: {class_precision:.2%}")
        print(f"  å¬å›ç‡: {class_recall:.2%}")
        print(f"  F1åˆ†æ•°: {class_f1:.2%}")
    
    # è®¡ç®—å®å¹³å‡å’Œå¾®å¹³å‡
    macro_precision = sum(precision) / num_classes
    macro_recall = sum(recall) / num_classes
    macro_f1 = sum(f1) / num_classes
    
    # å¾®å¹³å‡ï¼ˆåŸºäºæ€»TPã€FPã€FNï¼‰
    total_tp = sum(confusion_matrix[i][i] for i in range(num_classes))
    total_fp = sum(confusion_matrix[j][i] for i in range(num_classes) for j in range(num_classes) if j != i)
    total_fn = sum(confusion_matrix[i][j] for i in range(num_classes) for j in range(num_classes) if j != i)
    
    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0
    
    # æ€»ä½“å‡†ç¡®ç‡
    overall_accuracy = total_tp / len(all_true_labels) if len(all_true_labels) > 0 else 0
    
    print("\n===== æ€»ä½“æŒ‡æ ‡ =====")
    print(f"æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.2%}")
    print(f"å®å¹³å‡ç²¾ç¡®ç‡: {macro_precision:.2%}")
    print(f"å®å¹³å‡å¬å›ç‡: {macro_recall:.2%}")
    print(f"å®å¹³å‡F1åˆ†æ•°: {macro_f1:.2%}")
    print(f"å¾®å¹³å‡ç²¾ç¡®ç‡: {micro_precision:.2%}")
    print(f"å¾®å¹³å‡å¬å›ç‡: {micro_recall:.2%}")
    print(f"å¾®å¹³å‡F1åˆ†æ•°: {micro_f1:.2%}")
    
    # è¯†åˆ«è¡¨ç°æœ€å·®çš„ç±»åˆ«
    worst_class_idx = f1.index(min(f1))
    print(f"\n===== è¡¨ç°æœ€å·®çš„ç±»åˆ« =====")
    print(f"ç±»åˆ«: {category_names[worst_class_idx]}")
    print(f"F1åˆ†æ•°: {f1[worst_class_idx]:.2%}")
    
    # è¯†åˆ«å¸¸è§çš„é”™è¯¯é¢„æµ‹
    print("\n===== å¸¸è§é”™è¯¯é¢„æµ‹ =====")
    for i in range(num_classes):
        for j in range(num_classes):
            if i != j and confusion_matrix[i][j] > 0:
                print(f"{category_names[i]} è¢«è¯¯åˆ¤ä¸º {category_names[j]}: {confusion_matrix[i][j]} æ¬¡")
    
    # è¿”å›è¯„ä¼°ç»“æœ
    evaluation_results = {
        'confusion_matrix': confusion_matrix,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'accuracy': accuracy,
        'macro_precision': macro_precision,
        'macro_recall': macro_recall,
        'macro_f1': macro_f1,
        'micro_precision': micro_precision,
        'micro_recall': micro_recall,
        'micro_f1': micro_f1,
        'overall_accuracy': overall_accuracy,
        'worst_class': category_names[worst_class_idx],
        'worst_class_f1': f1[worst_class_idx],
        'all_true_labels': all_true_labels,
        'all_pred_labels': all_pred_labels,
        'all_pred_probs': all_pred_probs,
        'image_paths': image_paths
    }
    
    return evaluation_results

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
def visualize_predictions():
    """å¯è§†åŒ–æ¨¡å‹å¯¹ä¸åŒç±»åˆ«çš„é¢„æµ‹ç»“æœ"""
    # è·å–æ¯ä¸ªç±»åˆ«çš„ç¤ºä¾‹å›¾åƒ
    categories = [1, 2, 3]
    category_names = CONFIG['class_names']
    
    fig, axes = plt.subplots(len(categories), 4, figsize=(15, 15))
    
    for i, cat in enumerate(categories):
        cat_dir = os.path.join(TRAIN_IMG_PATH, str(cat))
        if not os.path.exists(cat_dir):
            continue
        
        images = [os.path.join(cat_dir, f) for f in os.listdir(cat_dir) if f.endswith('.png')][:4]
        
        for j, img_path in enumerate(images):
            # è¯»å–å›¾åƒ
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # æ¨¡å‹é¢„æµ‹
            pred_label, pred_prob = test_model(img_path)
            
            # è®¾ç½®æ ‡é¢˜
            # ç±»åˆ«ç›®å½•: 1->circle(ç´¢å¼•0), 2->slider(ç´¢å¼•1), 3->spinner(ç´¢å¼•2)
            true_idx = cat - 1
            true_name = category_names[true_idx]
            pred_name = category_names[pred_label]
            
            if pred_name == true_name:
                title_color = 'green'
            else:
                title_color = 'red'
            
            axes[i, j].imshow(img)
            axes[i, j].set_title(f"çœŸå®: {true_name}\né¢„æµ‹: {pred_name} ({pred_prob:.4f})", 
                              color=title_color, fontsize=12)
            axes[i, j].axis('off')
    
    plt.tight_layout()
    plt.savefig('prediction_visualization.png')
    print("\nğŸ“Š é¢„æµ‹ç»“æœå¯è§†åŒ–å·²ä¿å­˜ä¸º prediction_visualization.png")

# ä¸»å‡½æ•°
if __name__ == "__main__":
    # è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—è¯¦ç»†æŒ‡æ ‡
    evaluation_results = evaluate_model_performance()
    
    # å¯è§†åŒ–é¢„æµ‹ç»“æœ
    visualize_predictions()
    
    # ç”Ÿæˆæ”¹è¿›å»ºè®®
    print("\n===== æ¨¡å‹æ”¹è¿›å»ºè®® =====")
    print("1. æ•°æ®å¢å¼ºç­–ç•¥ï¼š")
    print("   - å¯¹spinnerç±»åˆ«è¿›è¡Œæ›´å¤šçš„æ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬æ—‹è½¬ã€ç¼©æ”¾ã€äº®åº¦è°ƒæ•´ç­‰")
    print("   - ç†ç”±ï¼šspinnerç±»åˆ«çš„æ ·æœ¬æ•°é‡è¾ƒå°‘ï¼Œä¸”ä¸sliderç±»åˆ«ç‰¹å¾ç›¸ä¼¼ï¼Œéœ€è¦æ›´å¤šå¤šæ ·åŒ–æ ·æœ¬")
    print("   - é¢„æœŸæ•ˆæœï¼šæé«˜spinnerç±»åˆ«çš„å¬å›ç‡å’ŒF1åˆ†æ•°ï¼Œå‡å°‘ä¸sliderçš„æ··æ·†")
    
    print("\n2. ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–ï¼š")
    print("   - å¢åŠ spinnerç‰¹æœ‰çš„ç‰¹å¾æå–ï¼Œå¦‚æ—‹è½¬çº¿æ¡ã€å†…å¤–åœ†ç»“æ„ç­‰")
    print("   - ç†ç”±ï¼šå½“å‰æ¨¡å‹å¯èƒ½æ²¡æœ‰å……åˆ†æ•æ‰spinnerçš„ç‹¬ç‰¹ç‰¹å¾")
    print("   - é¢„æœŸæ•ˆæœï¼šå¢å¼ºæ¨¡å‹å¯¹spinnerçš„è¯†åˆ«èƒ½åŠ›")
    
    print("\n3. æ¨¡å‹ç»“æ„è°ƒæ•´ï¼š")
    print("   - å¢åŠ æ¨¡å‹çš„æ·±åº¦æˆ–å®½åº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†ç±»å¤´éƒ¨åˆ†")
    print("   - ç†ç”±ï¼šå½“å‰æ¨¡å‹å¯èƒ½å®¹é‡ä¸è¶³ï¼Œæ— æ³•åŒºåˆ†ç›¸ä¼¼çš„ç±»åˆ«")
    print("   - é¢„æœŸæ•ˆæœï¼šæé«˜æ¨¡å‹çš„åˆ†ç±»èƒ½åŠ›ï¼Œå‡å°‘è¯¯åˆ¤")
    
    print("\n4. è¶…å‚æ•¸èª¿å„ªï¼š")
    print("   - è°ƒæ•´å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ï¼Œå°è¯•æ›´å¤§çš„åˆå§‹å­¦ä¹ ç‡")
    print("   - å¢åŠ è®­ç»ƒè½®æ•°ï¼Œè®©æ¨¡å‹æœ‰æ›´å¤šæ—¶é—´å­¦ä¹ spinnerç‰¹å¾")
    print("   - ç†ç”±ï¼šå½“å‰è®­ç»ƒè½®æ•°å¯èƒ½ä¸è¶³ï¼Œæ¨¡å‹å°šæœªå……åˆ†æ”¶æ•›")
    print("   - é¢„æœŸæ•ˆæœï¼šæé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½")
    
    print("\n5. ç±»åˆ«æƒé‡è°ƒæ•´ï¼š")
    print("   - è¿›ä¸€æ­¥å¢åŠ spinnerç±»åˆ«çš„æƒé‡ï¼Œå¦‚ä»1.5è°ƒæ•´åˆ°2.0")
    print("   - ç†ç”±ï¼šspinnerç±»åˆ«è¡¨ç°æœ€å·®ï¼Œéœ€è¦æ›´å¤šå…³æ³¨")
    print("   - é¢„æœŸæ•ˆæœï¼šæé«˜spinnerç±»åˆ«çš„å¬å›ç‡")
    
    print("\næµ‹è¯•å®Œæˆï¼")
